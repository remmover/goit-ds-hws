{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-22T16:45:28.525519Z",
     "start_time": "2025-02-22T16:45:28.388341Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "%matplotlib inline"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m layers, models\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Завантаження\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Нормалізація та розширення до 3 каналів\n",
    "x_train = np.stack([x_train] * 3, axis=-1) / 255.0\n",
    "x_test = np.stack([x_test] * 3, axis=-1) / 255.0\n",
    "\n",
    "# Масштабування зображень до 224x224 (для VGG16)\n",
    "x_train = np.array([resize(img, (32, 32)) for img in x_train])\n",
    "x_test = np.array([resize(img, (32, 32)) for img in x_test])\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "id": "2f349255ca2b0e70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image_input = tf.keras.layers.Input(shape=(32,32, 3)) \n",
    "baseModel_VGG_16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_tensor=image_input) \n",
    "\n",
    "for layer in baseModel_VGG_16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "baseModel_VGG_16.summary()  \n",
    "\n",
    "for layer in baseModel_VGG_16.layers:\n",
    "    layer.trainable = True"
   ],
   "id": "7994e536a44e98a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_final = Sequential([\n",
    "    baseModel_VGG_16,\n",
    "    Flatten(),\n",
    "    Dense(units=1000, activation='relu'),\n",
    "    Dense(units=800, activation='relu'),\n",
    "    Dense(units=400, activation='relu'),\n",
    "    Dense(units=200, activation='relu'),\n",
    "    Dense(units=100, activation='relu'),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_final.summary()"
   ],
   "id": "8b4af428c6cbffe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_learning_rate = 0.0001  \n",
    "optimizer = Adam(learning_rate=base_learning_rate, clipvalue=1.0)\n",
    "model_final.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "id": "454c383a4e5de10e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# training the Model with call back along with test and training data on a batch size of 128\n",
    "history = model_final.fit(np.asarray(x_train),\n",
    "                          np.asarray(y_train),\n",
    "                          validation_split=0.1,\n",
    "                          epochs=5,\n",
    "                          batch_size=32) "
   ],
   "id": "3a36b006f4b4399b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Сохранение истории в файл\n",
    "with open('vgg16_history.json', 'w') as f:\n",
    "    json.dump(history.history, f)"
   ],
   "id": "1b6679dab9ad974c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "with open('vgg16_history.json', 'r') as f:\n",
    "    history_data = json.load(f)\n",
    "\n",
    "# Построение графика точности\n",
    "plt.plot(history_data['accuracy'], label='Точность на обучающем наборе')\n",
    "plt.plot(history_data['val_accuracy'], label='Точность на валидационном наборе')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Точность')\n",
    "plt.legend()\n",
    "plt.title('График точности')\n",
    "plt.show()\n",
    "\n",
    "# Построение графика потерь\n",
    "plt.plot(history_data['loss'], label='Потери на обучающем наборе')\n",
    "plt.plot(history_data['val_loss'], label='Потери на валидационном наборе')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Потери')\n",
    "plt.legend()\n",
    "plt.title('График потерь')\n",
    "plt.show()"
   ],
   "id": "b50c612dc539a8de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_final.save('fashion_mnist_fine_tuned_vgg16.h5')\n",
    "model_final.save_weights('fashion_mnist_fine_tuned_vgg16_weights.h5')"
   ],
   "id": "2e37c8507620fb37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Висновки:\n",
    "VGG16 - складніша модель, дає дуже хороші результати, але навчання займає багато часу, і вона може бути перевантаженою для простих задач.\n",
    "Згорткова модель -  швидше навчається і дає схожі результати, але з меншою складністю. \n",
    "Вона може бути хорошим варіантом для задач, де важлива швидкість і ефективність, але при цьому не дуже важлива точність, яка може просідати"
   ],
   "id": "ff52aa2c0129179"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
